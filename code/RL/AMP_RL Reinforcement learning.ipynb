{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1175d61c-7f9e-48c8-bbe5-8edf01beb74a",
   "metadata": {},
   "source": [
    "### GPU setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b07c1fb-2ed1-4e00-909c-c2abf50d6ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1121d293-3566-4d1b-9943-4f541969996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d513f-b463-435f-9859-98f6f747be6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import requests\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR, StepLR\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "sys.path.append('../../code/Common_modules')\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e46722-0361-4970-938c-a67a99ec5908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import set_randomness\n",
    "set_randomness()\n",
    "pd.options.display.max_colwidth = 999\n",
    "SEED = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ce15f2-0176-45cf-8e90-18790a8ef01b",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bf4a48-4b80-47d7-b00b-448230c15684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from dataclasses import dataclass, asdict\n",
    "from transformers import EsmTokenizer, EsmModel\n",
    "from Tokenize_modules import Vocabulary, PeptideTokenizer, locate_specials, locate_non_standard_AA\n",
    "\n",
    "ESM_tokenizer = EsmTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "vocab = Vocabulary(file_name = os.path.join('../../data','vocab/vocab.txt'))\n",
    "peptide_tokenizer = PeptideTokenizer(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bab749-00c8-4c90-9c4d-9d3c9d7cc50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RL_GPT_modules import GPTConfig\n",
    "Total_species_list = ['Abaumannii','Bsubtilis','Ecoli','Efaecalis','Enterobactercloacae','Kpneumoniae','Paeruginosa','Saureus']\n",
    "gpt_conf = GPTConfig(voc = vocab)\n",
    "data_path = gpt_conf.data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa99925-d720-4282-bf7b-bc81922a11ad",
   "metadata": {},
   "source": [
    "### AMP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ccf17-6628-4273-8f08-94378aa146ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_amp_csv = pd.read_csv(os.path.join(data_path,\"multi_train_35_0.8.csv\"))\n",
    "remove_idx = train_amp_csv[train_amp_csv['sequence'].str.contains('U|Z|B|X')]\n",
    "AMP_train_df = train_amp_csv.drop(remove_idx.index)\n",
    "AMP_finetune_seq = AMP_train_df.sequence.unique().tolist()\n",
    "len(AMP_finetune_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ff11db",
   "metadata": {},
   "source": [
    "### PrefixProt MIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bfd26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_MIC  = pd.read_csv('../../data/Prefix_list.csv')\n",
    "Prefix_Pred = prefix_MIC['Escherichia coli'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34cbd8b-c533-4165-9327-471e8264b5d6",
   "metadata": {},
   "source": [
    "### HemoDL (GPU 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7156de5-069e-4464-9a92-bb04863819cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from features import fs_encode\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5Model,T5EncoderModel\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import argparse\n",
    "\n",
    "model_esm, alphabet = torch.hub.load(\"facebookresearch/esm:main\", \"esm2_t33_650M_UR50D\")\n",
    "model_esm = model_esm.to(device)\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_uniref50',do_lower_case=False)\n",
    "model_t5 = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\").to(device)\n",
    "\n",
    "model_fs = lgb.Booster(model_file=\"../../Hemolysis_predictor/source/models/model.fs\")\n",
    "model_tr = lgb.Booster(model_file=\"../../Hemolysis_predictor/source/models/model.transformer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcaa92a-8c80-4f4b-aec2-ab7aafa3f4bc",
   "metadata": {},
   "source": [
    "### Species select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaa6369-2578-4d3e-8906-d22e2a56e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MIC_predictor import get_features, RegressionModel\n",
    "from Utils import get_classify, classify_AMP, ClassificationModel\n",
    "genome_features = torch.load(gpt_conf.genome_feature_path)\n",
    "species_35 = pd.read_csv(gpt_conf.species_path)\n",
    "species = species_35['species'].unique()\n",
    "genome_feats = get_features([species[0]], genome_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f96763-2759-437a-92da-1d14e9b24021",
   "metadata": {},
   "source": [
    "### Regression & Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062dff3f-e757-464c-9fea-e831dab6492b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cls_model = ClassificationModel(hidden_feat = 256, pooling = 'CLS')\n",
    "cls_model.load_state_dict(torch.load('../../AMP_classifier/LMPred.pth',map_location=gpt_conf.device),strict=False)\n",
    "cls_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4259d3e-0349-4b05-91fb-4984d2b6883d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_model = RegressionModel(hidden_feat = 256, pooling = 'CLS')\n",
    "reg_model.load_state_dict(torch.load('../../MIC_predictor/pepESM_90_35_species_500.pth',map_location=device),strict=False)\n",
    "reg_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7453e724-7e45-48d0-9fa9-13d482a58d7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Reinforcement learning for Seen species**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff1525-7ec0-4937-8362-281019e41fb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass, asdict\n",
    "from transformers import EsmTokenizer, EsmModel\n",
    "from tqdm import tqdm\n",
    "from Levenshtein import distance\n",
    "from Levenshtein import ratio\n",
    "\n",
    "from Utils import count_parameters, estimate_and_update, get_num_amino_acid\n",
    "from Tokenize_modules import sequence_to_input\n",
    "from MIC_predictor import get_reward_logp\n",
    "from Hemolysis_predictor import classify_Hemo\n",
    "from RL_GPT_modules import GPTGenerator, GPTGeneratorConfig, BaseGPTWrapper\n",
    "from RL_modules import GradientTracker, ExperienceMemory, Reinforcement\n",
    "\n",
    "AMP_finetuned_path = '../../ckpt/Pretrain/AMP_pretrain/Finetune_Pareto_ckpt20.ckpt'\n",
    "genome_feature_index_list = [7, 4, 0, 8, 13, 5, 2, 1]\n",
    "\n",
    "for spc_idx in range(0,2):\n",
    "    for times in [1, 2, 3, 4]:\n",
    "        for kl_coef in [0.0001, 0.01, 0.05, 0.1]:\n",
    "            RL_lr = 5e-4\n",
    "            sample_num = 2000\n",
    "            set_randomness()\n",
    "            pd.options.display.max_colwidth = 999\n",
    "            SEED = 2021\n",
    "            mic_value = 1.5\n",
    "            hemo_value = 0.5\n",
    "            gpt_conf.reward_thres_reg = mic_value\n",
    "            gpt_conf.reward_thres_hemo = hemo_value\n",
    "            gpt_conf.RL_ckpt_path = f\"../../ckpt/RL/{Total_species_list[spc_idx]}/Replay_buffer_Top_{times}_KL_coef_{kl_coef}/\"\n",
    "            os.makedirs(gpt_conf.RL_ckpt_path, exist_ok = True)\n",
    "            print(f'===============MIC_threshold : {gpt_conf.reward_thres_reg}, Hemo_threshold : {gpt_conf.reward_thres_hemo}, Learning_rate : {RL_lr}, Species_name : {Total_species_list[spc_idx]}===============')\n",
    "\n",
    "            gpt_conf.gen_samples = sample_num\n",
    "            gpt_conf.n_iterations = 40\n",
    "            gpt_conf.rein_opt_lr = RL_lr\n",
    "\n",
    "            conf_1 = GPTGeneratorConfig(gpt_conf=GPTConfig(voc = vocab),lr_mult=0.95)\n",
    "            basegpt_1 = BaseGPTWrapper(conf_1.gpt_conf)\n",
    "            prior = GPTGenerator(basegpt_1, conf_1)\n",
    "            prior = prior.construct_by_ckpt_dict(torch.load(AMP_finetuned_path),vocab)\n",
    "            \n",
    "            conf_2 = GPTGeneratorConfig(gpt_conf=GPTConfig(voc = vocab),lr_mult=0.95)\n",
    "            basegpt_2 = BaseGPTWrapper(conf_2.gpt_conf)\n",
    "            generator = GPTGenerator(basegpt_2, conf_2)\n",
    "            generator = generator.construct_by_ckpt_dict(torch.load(AMP_finetuned_path),vocab)\n",
    "\n",
    "            genome_feats = get_features([species[genome_feature_index_list[spc_idx]]], genome_features)\n",
    "\n",
    "            n_to_generate = gpt_conf.gen_samples\n",
    "            n_iterations = gpt_conf.n_iterations\n",
    "\n",
    "            for param in prior.base_gpt.gpt.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            for param in generator.base_gpt.gpt.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            for target_module in generator.base_gpt.gpt.lora_layers:\n",
    "                for param in generator.base_gpt.gpt.lora_layers[target_module].parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "            for name, param in generator.base_gpt.gpt.named_parameters():\n",
    "                print(f'{name} Grad : {param.requires_grad}')\n",
    "\n",
    "            RL_logp = Reinforcement(generator, reg_model, get_reward_logp, classify_Hemo, rein_opt_lr = gpt_conf.rein_opt_lr, genome_feats = genome_feats)\n",
    "            gradient_tracker = GradientTracker(RL_logp.generator.base_gpt.gpt)\n",
    "\n",
    "            total_params, trainable_params = count_parameters(RL_logp.generator.base_gpt.gpt)\n",
    "            trainable_percent = (trainable_params / total_params)\n",
    "            print(f\"trainable params: {trainable_params:,} || all params: {total_params:,} || trainable%: {trainable_percent:.4f}\")\n",
    "\n",
    "            rewards = []\n",
    "            MIC_rewards = []\n",
    "            Hemo_rewards = []\n",
    "            rl_losses = []\n",
    "\n",
    "            memory = ExperienceMemory(capacity=5000)\n",
    "\n",
    "            for i in range(n_iterations):\n",
    "                print(f'===============Current Epoch : {i}===============')\n",
    "                generate = np.array(RL_logp.generator.sample_decode(ssize=n_to_generate, msl=50, bs=128))\n",
    "                print(generate)\n",
    "                print(f'generate number : {len(list(set(generate)))}')\n",
    "                generate = list(generate)\n",
    "                mic_preds, _ = get_reward_logp(generate,reg_model,genome_feats)\n",
    "                hemo_preds, _ = classify_Hemo(generate)\n",
    "\n",
    "                memory.add_sequences(generate, mic_preds, hemo_preds)\n",
    "                new_gen, _, _ = memory.get_buffer(sample_size = 100, times = times)\n",
    "                generate = random.sample(generate, 200)\n",
    "                generate = generate + new_gen\n",
    "\n",
    "                classes, _ = classify_AMP(cls_model, generate, ESM_tokenizer)\n",
    "                classes = np.array([1 if cls >= gpt_conf.reward_thres_cls else 0 for cls in classes]) \n",
    "                print(f'The ratio of generated AMP samples : {classes.sum() / len(classes)}')  \n",
    "\n",
    "                train_data_loader = DataLoader(list(set(generate)), batch_size=gpt_conf.batch_size,\n",
    "                                      shuffle=True, drop_last=True, collate_fn=None)\n",
    "\n",
    "                cur_loss, cur_reward, MIC_mean_reward, Hemo_mean_reward = RL_logp.policy_gradient(train_data_loader, prior, epoch = i, kl_coef = kl_coef, gradient_tracker = gradient_tracker, grad_clipping = 1.0, gamma = gpt_conf.gamma)\n",
    "                rewards.append(cur_reward)\n",
    "                MIC_rewards.append(MIC_mean_reward)\n",
    "                Hemo_rewards.append(Hemo_mean_reward)\n",
    "                rl_losses.append(cur_loss)\n",
    "\n",
    "                RL_LoRA_weight_path = gpt_conf.RL_ckpt_path+f\"{Total_species_list[spc_idx]}_AMP_RL_LoRA_Weight_ES_ME_40_{gpt_conf.reward_thres_hemo}_{gpt_conf.reward_thres_reg}_{gpt_conf.rein_opt_lr}_{gpt_conf.gen_samples}_%d.pth\"%(i)\n",
    "                RL_logp.generator.base_gpt.gpt.save_lora_weights(RL_LoRA_weight_path)\n",
    "\n",
    "                # Print max gradients\n",
    "                gradient_tracker.print_max_grads()\n",
    "\n",
    "                plt.plot(rewards)\n",
    "                plt.xlabel('Training iteration')\n",
    "                plt.ylabel('Average reward')\n",
    "                plt.show()\n",
    "                plt.plot(MIC_rewards)\n",
    "                plt.xlabel('Training iteration')\n",
    "                plt.ylabel('Average MIC reward')\n",
    "                plt.show()\n",
    "                plt.plot(Hemo_rewards)\n",
    "                plt.xlabel('Training iteration')\n",
    "                plt.ylabel('Average Hemo reward')\n",
    "                plt.show()\n",
    "                plt.plot(rl_losses)\n",
    "                plt.xlabel('Training iteration')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.show()\n",
    "\n",
    "                result = estimate_and_update(RL_logp.generator, reg_model, cls_model ,tokenizer = tokenizer,n_to_generate=1000, genome_feat = genome_feats) \n",
    "                temp = [len(data) for data in result[0]]\n",
    "                counter_object = Counter(temp)\n",
    "                plt.bar(list(counter_object.keys()), list(counter_object.values()))\n",
    "                plt.xlabel('Length distribution of Peptides')\n",
    "                plt.ylabel('Number of Samples by length')\n",
    "                plt.show()\n",
    "\n",
    "                finetune_composition = get_num_amino_acid(list(set(result[0].tolist())))\n",
    "                database_composition = get_num_amino_acid(list(set(AMP_finetune_seq)))\n",
    "\n",
    "                del finetune_composition[' ']\n",
    "                del database_composition[' ']\n",
    "\n",
    "                plt.bar(height = finetune_composition.values(), x=finetune_composition.keys(), label = 'optimized', alpha=0.3)\n",
    "                plt.bar(height = database_composition.values(), x=database_composition.keys(), label = 'database', alpha=0.3)\n",
    "                plt.legend()\n",
    "                plt.title('Amino acid composition')\n",
    "                plt.show()\n",
    "\n",
    "                # Diversity\n",
    "                LD_array = np.zeros((len(result[0].tolist()),len(result[0].tolist())))\n",
    "                for row_idx, row_data in enumerate(result[0].tolist()):\n",
    "                    for col_idx, col_data in enumerate(result[0].tolist()):\n",
    "                        LD_array[row_idx][col_idx] = 1-ratio(row_data,col_data)\n",
    "\n",
    "                diversity_values = np.tril(LD_array)[np.tril(LD_array).nonzero()].mean()\n",
    "\n",
    "                # Novelty\n",
    "                novelty_values = 0\n",
    "                for data in list(set(result[0].tolist())):\n",
    "                    if data not in train_amp_csv.sequence.tolist():\n",
    "                        novelty_values += 1\n",
    "\n",
    "                # Uniqueness\n",
    "                unique_values = len(list(set(result[0].tolist())))\n",
    "                print(f'Uniqueness : {unique_values}, Diversity : {diversity_values} , Novelty : {novelty_values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac444526-a90c-4164-b1db-e789b39efe2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f905467",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_ckpt_path = '../../ckpt/RL/Best_ckpt/Seen_species'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da2dc3c-d2ba-475b-b170-cdb3d8ca1ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMP_pretrained_path = '../../ckpt/Pretrain/AMP_pretrain/Finetune_Pareto_ckpt20.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e35ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass, asdict\n",
    "from transformers import EsmTokenizer, EsmModel\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from Levenshtein import distance\n",
    "from Levenshtein import ratio\n",
    "from MIC_predictor import get_reward_logp\n",
    "from Hemolysis_predictor import classify_Hemo\n",
    "from Utils import classify_AMP, plot_hist, calculate_overlap_ratio\n",
    "from RL_GPT_modules import GPTGenerator, GPTGeneratorConfig, BaseGPTWrapper\n",
    "from Tokenize_modules import Vocabulary, PeptideTokenizer, locate_specials, locate_non_standard_AA\n",
    "\n",
    "ckpt_path_list = glob(os.path.join(Best_ckpt_path, '*.pth'))\n",
    "\n",
    "for path_idx, path in enumerate(ckpt_path_list):\n",
    "    save_species_name = os.path.basename(ckpt_path_list[path_idx]).split('_')[0]\n",
    "\n",
    "    conf = GPTGeneratorConfig(gpt_conf=GPTConfig(voc = vocab),lr_mult=0.95)\n",
    "    basegpt = BaseGPTWrapper(conf.gpt_conf)\n",
    "    generator = GPTGenerator(basegpt, conf)\n",
    "    generator = generator.construct_by_ckpt_dict(torch.load(AMP_pretrained_path),vocab)\n",
    "    generator.base_gpt.gpt.load_lora_weights(path)\n",
    "\n",
    "    generator.base_gpt.gpt.eval()\n",
    "    with torch.no_grad():\n",
    "        sampled = generator.sample_decode(ssize=1000, msl=50, bs=20)\n",
    "        display(sampled)\n",
    "    generate = list(sampled)\n",
    "\n",
    "    n_to_generate = gpt_conf.gen_samples\n",
    "    ESM_tokenizer = EsmTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "    vocab = Vocabulary(file_name = os.path.join('../../data','vocab/vocab.txt'))\n",
    "    peptide_tokenizer = PeptideTokenizer(vocab)\n",
    "\n",
    "    nndd = [len(data) for data in generate]\n",
    "    print(f'min number of generation : {min(nndd)}')\n",
    "    preds,_  = get_reward_logp(generate, reg_model, genome_feature = genome_feats)\n",
    "    classes, _ = classify_AMP(cls_model, generate, ESM_tokenizer)\n",
    "    hemo_pred, _ = classify_Hemo(generate)\n",
    "    classes = np.array([1 if data >= 0.5 else 0 for data in classes])\n",
    "    micpreds = np.array([1 if data <= gpt_conf.reward_thres_reg else 0 for data in preds])\n",
    "    nonhemo = np.array([1 if data <= gpt_conf.reward_thres_hemo else 0 for data in hemo_pred])\n",
    "    plot_hist(preds, n_to_generate)\n",
    "    print(f'The ratio of generated AMP : {classes.sum()/len(classes)}')\n",
    "    print(f'The ratio of non-hemolytic generated peptides : {nonhemo.sum()/len(nonhemo)}')\n",
    "    both_ratio = calculate_overlap_ratio(micpreds, nonhemo)\n",
    "    print(f'The ratio of Both (Low MIC adn Low Hemolysis) peptides : {both_ratio}')\n",
    "    print(f'The ratio of non-redundant peptides : {len(list(set(generate)))/len(generate)}')\n",
    "\n",
    "    finetune_composition = get_num_amino_acid(list(set(generate)))\n",
    "    database_composition = get_num_amino_acid(list(set(AMP_finetune_seq)))\n",
    "\n",
    "    del finetune_composition[' ']\n",
    "    del database_composition[' ']\n",
    "\n",
    "    plt.bar(height = finetune_composition.values(), x=finetune_composition.keys(), label = 'optimized', alpha=0.3)\n",
    "    plt.bar(height = database_composition.values(), x=database_composition.keys(), label = 'database', alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.title('Amino acid composition')\n",
    "    plt.show()\n",
    "\n",
    "    # Diversity\n",
    "    LD_array = np.zeros((len(generate),len(generate)))\n",
    "    for row_idx, row_data in enumerate(generate):\n",
    "        for col_idx, col_data in enumerate(generate):\n",
    "            LD_array[row_idx][col_idx] = 1-ratio(row_data,col_data)\n",
    "\n",
    "    diversity_values = np.tril(LD_array)[np.tril(LD_array).nonzero()].mean()\n",
    "\n",
    "    # Novelty\n",
    "    novelty_values = 0\n",
    "    for data in list(set(generate)):\n",
    "        if data not in train_amp_csv.sequence.tolist():\n",
    "            novelty_values += 1\n",
    "\n",
    "    # Uniqueness\n",
    "    unique_values = len(list(set(generate)))\n",
    "    print(f'Uniqueness : {unique_values}, Diversity : {diversity_values} , Novelty : {novelty_values}')\n",
    "\n",
    "    npy_path = '../../Generated_samples'\n",
    "\n",
    "    np.save(os.path.join(npy_path,f'{save_species_name}_1000.npy'),np.array(sampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d186fabf-8a6c-4f00-a77c-d82dfeacae4a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Reinforcement learning for Unseen species**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ce6300-f096-4c0f-972e-fa871eb76acf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Unseen dataset and genome features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dee2a8-e21d-4508-b50d-38730eabdcdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "external_data = pd.read_csv(os.path.join('../../data','Unseen_data','external.csv'))\n",
    "external_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f98c8d-70a9-4526-9179-222a8b0c35ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_features = torch.load(gpt_conf.genome_feature_path)\n",
    "species_10 = external_data\n",
    "species = species_10['species'].unique()\n",
    "genome_feats = get_features([species[0]], genome_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0253aeb-8034-4efc-b234-6a05944fa5e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Training unseen species**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b3c38-7402-4f3c-a105-d49418f3e779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass, asdict\n",
    "from transformers import EsmTokenizer, EsmModel\n",
    "from tqdm import tqdm\n",
    "from Levenshtein import distance\n",
    "from Levenshtein import ratio\n",
    "\n",
    "from Utils import count_parameters, estimate_and_update, get_num_amino_acid\n",
    "from Tokenize_modules import sequence_to_input\n",
    "from MIC_predictor import get_reward_logp\n",
    "from Hemolysis_predictor import classify_Hemo\n",
    "from RL_GPT_modules import GPTGenerator, GPTGeneratorConfig, BaseGPTWrapper\n",
    "from RL_modules import GradientTracker, ExperienceMemory, Reinforcement\n",
    "\n",
    "AMP_finetuned_path = '../../ckpt/Pretrain/AMP_pretrain/Finetune_Pareto_ckpt20.ckpt'\n",
    "Total_species_list = species_10['species'].unique()\n",
    "genome_feature_index_list = range(len(Total_species_list))\n",
    "\n",
    "for spc_idx in range(0,2):\n",
    "    for times in [1, 2, 3, 4]:\n",
    "        for kl_coef in [0.0001, 0.01, 0.05, 0.1]:\n",
    "            RL_lr = 5e-4\n",
    "            sample_num = 2000\n",
    "            set_randomness()\n",
    "            pd.options.display.max_colwidth = 999\n",
    "            SEED = 2021\n",
    "            mic_value = 1.5\n",
    "            hemo_value = 0.5\n",
    "            gpt_conf.reward_thres_reg = mic_value\n",
    "            gpt_conf.reward_thres_hemo = hemo_value\n",
    "            gpt_conf.RL_ckpt_path = f\"../../ckpt/RL/{Total_species_list[spc_idx]}/Replay_buffer_Top_{times}_KL_coef_{kl_coef}/\"\n",
    "            os.makedirs(gpt_conf.RL_ckpt_path, exist_ok = True)\n",
    "            print(f'===============MIC_threshold : {gpt_conf.reward_thres_reg}, Hemo_threshold : {gpt_conf.reward_thres_hemo}, Learning_rate : {RL_lr}, Species_name : {Total_species_list[spc_idx]}===============')\n",
    "\n",
    "            gpt_conf.gen_samples = sample_num\n",
    "            gpt_conf.n_iterations = 40\n",
    "            gpt_conf.rein_opt_lr = RL_lr\n",
    "\n",
    "            conf_1 = GPTGeneratorConfig(gpt_conf=GPTConfig(voc = vocab),lr_mult=0.95)\n",
    "            basegpt_1 = BaseGPTWrapper(conf_1.gpt_conf)\n",
    "            prior = GPTGenerator(basegpt_1, conf_1)\n",
    "            prior = prior.construct_by_ckpt_dict(torch.load(AMP_finetuned_path),vocab)\n",
    "            \n",
    "            conf_2 = GPTGeneratorConfig(gpt_conf=GPTConfig(voc = vocab),lr_mult=0.95)\n",
    "            basegpt_2 = BaseGPTWrapper(conf_2.gpt_conf)\n",
    "            generator = GPTGenerator(basegpt_2, conf_2)\n",
    "            generator = generator.construct_by_ckpt_dict(torch.load(AMP_finetuned_path),vocab)\n",
    "\n",
    "            genome_feats = get_features([species[genome_feature_index_list[spc_idx]]], genome_features)\n",
    "\n",
    "            n_to_generate = gpt_conf.gen_samples\n",
    "            n_iterations = gpt_conf.n_iterations\n",
    "\n",
    "            for param in prior.base_gpt.gpt.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            for param in generator.base_gpt.gpt.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            for target_module in generator.base_gpt.gpt.lora_layers:\n",
    "                for param in generator.base_gpt.gpt.lora_layers[target_module].parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "            for name, param in generator.base_gpt.gpt.named_parameters():\n",
    "                print(f'{name} Grad : {param.requires_grad}')\n",
    "\n",
    "            RL_logp = Reinforcement(generator, reg_model, get_reward_logp, classify_Hemo, rein_opt_lr = gpt_conf.rein_opt_lr, genome_feats = genome_feats)\n",
    "            gradient_tracker = GradientTracker(RL_logp.generator.base_gpt.gpt)\n",
    "\n",
    "            total_params, trainable_params = count_parameters(RL_logp.generator.base_gpt.gpt)\n",
    "            trainable_percent = (trainable_params / total_params)\n",
    "            print(f\"trainable params: {trainable_params:,} || all params: {total_params:,} || trainable%: {trainable_percent:.4f}\")\n",
    "\n",
    "            rewards = []\n",
    "            MIC_rewards = []\n",
    "            Hemo_rewards = []\n",
    "            rl_losses = []\n",
    "\n",
    "            memory = ExperienceMemory(capacity=5000)\n",
    "\n",
    "            for i in range(n_iterations):\n",
    "                print(f'===============Current Epoch : {i}===============')\n",
    "                generate = np.array(RL_logp.generator.sample_decode(ssize=n_to_generate, msl=50, bs=128))\n",
    "                print(generate)\n",
    "                print(f'generate number : {len(list(set(generate)))}')\n",
    "                generate = list(generate)\n",
    "                mic_preds, _ = get_reward_logp(generate,reg_model,genome_feats)\n",
    "                hemo_preds, _ = classify_Hemo(generate)\n",
    "\n",
    "                memory.add_sequences(generate, mic_preds, hemo_preds)\n",
    "                new_gen, _, _ = memory.get_buffer(sample_size = 100, times = times)\n",
    "                generate = random.sample(generate, 200)\n",
    "                generate = generate + new_gen\n",
    "\n",
    "                classes, _ = classify_AMP(cls_model, generate, ESM_tokenizer)\n",
    "                classes = np.array([1 if cls >= gpt_conf.reward_thres_cls else 0 for cls in classes]) \n",
    "                print(f'The ratio of generated AMP samples : {classes.sum() / len(classes)}')  \n",
    "\n",
    "                train_data_loader = DataLoader(list(set(generate)), batch_size=gpt_conf.batch_size,\n",
    "                                      shuffle=True, drop_last=True, collate_fn=None)\n",
    "\n",
    "                cur_loss, cur_reward, MIC_mean_reward, Hemo_mean_reward = RL_logp.policy_gradient(train_data_loader, prior, epoch = i, kl_coef = kl_coef, gradient_tracker = gradient_tracker, grad_clipping = 1.0, gamma = gpt_conf.gamma)\n",
    "                rewards.append(cur_reward)\n",
    "                MIC_rewards.append(MIC_mean_reward)\n",
    "                Hemo_rewards.append(Hemo_mean_reward)\n",
    "                rl_losses.append(cur_loss)\n",
    "\n",
    "                RL_LoRA_weight_path = gpt_conf.RL_ckpt_path+f\"{Total_species_list[spc_idx]}_AMP_RL_LoRA_Weight_ES_ME_40_{gpt_conf.reward_thres_hemo}_{gpt_conf.reward_thres_reg}_{gpt_conf.rein_opt_lr}_{gpt_conf.gen_samples}_%d.pth\"%(i)\n",
    "                RL_logp.generator.base_gpt.gpt.save_lora_weights(RL_LoRA_weight_path)\n",
    "\n",
    "                # Print max gradients\n",
    "                gradient_tracker.print_max_grads()\n",
    "\n",
    "                plt.plot(rewards)\n",
    "                plt.xlabel('Training iteration')\n",
    "                plt.ylabel('Average reward')\n",
    "                plt.show()\n",
    "                plt.plot(MIC_rewards)\n",
    "                plt.xlabel('Training iteration')\n",
    "                plt.ylabel('Average MIC reward')\n",
    "                plt.show()\n",
    "                plt.plot(Hemo_rewards)\n",
    "                plt.xlabel('Training iteration')\n",
    "                plt.ylabel('Average Hemo reward')\n",
    "                plt.show()\n",
    "                plt.plot(rl_losses)\n",
    "                plt.xlabel('Training iteration')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.show()\n",
    "\n",
    "                result = estimate_and_update(RL_logp.generator, reg_model, cls_model ,tokenizer = tokenizer,n_to_generate=1000, genome_feat = genome_feats) \n",
    "                temp = [len(data) for data in result[0]]\n",
    "                counter_object = Counter(temp)\n",
    "                plt.bar(list(counter_object.keys()), list(counter_object.values()))\n",
    "                plt.xlabel('Length distribution of Peptides')\n",
    "                plt.ylabel('Number of Samples by length')\n",
    "                plt.show()\n",
    "\n",
    "                finetune_composition = get_num_amino_acid(list(set(result[0].tolist())))\n",
    "                database_composition = get_num_amino_acid(list(set(AMP_finetune_seq)))\n",
    "\n",
    "                del finetune_composition[' ']\n",
    "                del database_composition[' ']\n",
    "\n",
    "                plt.bar(height = finetune_composition.values(), x=finetune_composition.keys(), label = 'optimized', alpha=0.3)\n",
    "                plt.bar(height = database_composition.values(), x=database_composition.keys(), label = 'database', alpha=0.3)\n",
    "                plt.legend()\n",
    "                plt.title('Amino acid composition')\n",
    "                plt.show()\n",
    "\n",
    "                # Diversity\n",
    "                LD_array = np.zeros((len(result[0].tolist()),len(result[0].tolist())))\n",
    "                for row_idx, row_data in enumerate(result[0].tolist()):\n",
    "                    for col_idx, col_data in enumerate(result[0].tolist()):\n",
    "                        LD_array[row_idx][col_idx] = 1-ratio(row_data,col_data)\n",
    "\n",
    "                diversity_values = np.tril(LD_array)[np.tril(LD_array).nonzero()].mean()\n",
    "\n",
    "                # Novelty\n",
    "                novelty_values = 0\n",
    "                for data in list(set(result[0].tolist())):\n",
    "                    if data not in train_amp_csv.sequence.tolist():\n",
    "                        novelty_values += 1\n",
    "\n",
    "                # Uniqueness\n",
    "                unique_values = len(list(set(result[0].tolist())))\n",
    "                print(f'Uniqueness : {unique_values}, Diversity : {diversity_values} , Novelty : {novelty_values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaecdb2-1a24-4875-8d09-51d0e434fcf3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae426bec-0fed-4d86-aea2-f462c0c6a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_ckpt_path = '../../ckpt/RL/Best_ckpt/Unseen_species'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d04da1a-7750-4b00-b6a7-c76a436b7063",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMP_pretrained_path = '../../ckpt/Pretrain/AMP_pretrain/Finetune_Pareto_ckpt20.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6fd389-a277-41f9-938f-30f29fe734c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass, asdict\n",
    "from transformers import EsmTokenizer, EsmModel\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from Levenshtein import distance\n",
    "from Levenshtein import ratio\n",
    "from MIC_predictor import get_reward_logp\n",
    "from Hemolysis_predictor import classify_Hemo\n",
    "from Utils import classify_AMP, plot_hist, calculate_overlap_ratio\n",
    "from RL_GPT_modules import GPTGenerator, GPTGeneratorConfig, BaseGPTWrapper\n",
    "from Tokenize_modules import Vocabulary, PeptideTokenizer, locate_specials, locate_non_standard_AA\n",
    "\n",
    "ckpt_path_list = glob(os.path.join(Best_ckpt_path, '*.pth'))\n",
    "\n",
    "for path_idx, path in enumerate(ckpt_path_list):\n",
    "    save_species_name = os.path.basename(ckpt_path_list[path_idx]).split('_')[0]\n",
    "\n",
    "    conf = GPTGeneratorConfig(gpt_conf=GPTConfig(voc = vocab),lr_mult=0.95)\n",
    "    basegpt = BaseGPTWrapper(conf.gpt_conf)\n",
    "    generator = GPTGenerator(basegpt, conf)\n",
    "    generator = generator.construct_by_ckpt_dict(torch.load(AMP_pretrained_path),vocab)\n",
    "    generator.base_gpt.gpt.load_lora_weights(path)\n",
    "\n",
    "    generator.base_gpt.gpt.eval()\n",
    "    with torch.no_grad():\n",
    "        sampled = generator.sample_decode(ssize=1000, msl=50, bs=20)\n",
    "        display(sampled)\n",
    "    generate = list(sampled)\n",
    "\n",
    "    n_to_generate = gpt_conf.gen_samples\n",
    "    ESM_tokenizer = EsmTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "    vocab = Vocabulary(file_name = os.path.join('../../data','vocab/vocab.txt'))\n",
    "    peptide_tokenizer = PeptideTokenizer(vocab)\n",
    "\n",
    "    nndd = [len(data) for data in generate]\n",
    "    print(f'min number of generation : {min(nndd)}')\n",
    "    preds,_  = get_reward_logp(generate, reg_model, genome_feature = genome_feats)\n",
    "    classes, _ = classify_AMP(cls_model, generate, ESM_tokenizer)\n",
    "    hemo_pred, _ = classify_Hemo(generate)\n",
    "    classes = np.array([1 if data >= 0.5 else 0 for data in classes])\n",
    "    micpreds = np.array([1 if data <= gpt_conf.reward_thres_reg else 0 for data in preds])\n",
    "    nonhemo = np.array([1 if data <= gpt_conf.reward_thres_hemo else 0 for data in hemo_pred])\n",
    "    plot_hist(preds, n_to_generate)\n",
    "    print(f'The ratio of generated AMP : {classes.sum()/len(classes)}')\n",
    "    print(f'The ratio of non-hemolytic generated peptides : {nonhemo.sum()/len(nonhemo)}')\n",
    "    both_ratio = calculate_overlap_ratio(micpreds, nonhemo)\n",
    "    print(f'The ratio of Both (Low MIC adn Low Hemolysis) peptides : {both_ratio}')\n",
    "    print(f'The ratio of non-redundant peptides : {len(list(set(generate)))/len(generate)}')\n",
    "\n",
    "    finetune_composition = get_num_amino_acid(list(set(generate)))\n",
    "    database_composition = get_num_amino_acid(list(set(AMP_finetune_seq)))\n",
    "\n",
    "    del finetune_composition[' ']\n",
    "    del database_composition[' ']\n",
    "\n",
    "    plt.bar(height = finetune_composition.values(), x=finetune_composition.keys(), label = 'optimized', alpha=0.3)\n",
    "    plt.bar(height = database_composition.values(), x=database_composition.keys(), label = 'database', alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.title('Amino acid composition')\n",
    "    plt.show()\n",
    "\n",
    "    # Diversity\n",
    "    LD_array = np.zeros((len(generate),len(generate)))\n",
    "    for row_idx, row_data in enumerate(generate):\n",
    "        for col_idx, col_data in enumerate(generate):\n",
    "            LD_array[row_idx][col_idx] = 1-ratio(row_data,col_data)\n",
    "\n",
    "    diversity_values = np.tril(LD_array)[np.tril(LD_array).nonzero()].mean()\n",
    "\n",
    "    # Novelty\n",
    "    novelty_values = 0\n",
    "    for data in list(set(generate)):\n",
    "        if data not in train_amp_csv.sequence.tolist():\n",
    "            novelty_values += 1\n",
    "\n",
    "    # Uniqueness\n",
    "    unique_values = len(list(set(generate)))\n",
    "    print(f'Uniqueness : {unique_values}, Diversity : {diversity_values} , Novelty : {novelty_values}')\n",
    "\n",
    "    npy_path = '../../Generated_samples'\n",
    "\n",
    "    np.save(os.path.join(npy_path,f'{save_species_name}_1000.npy'),np.array(sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e44c95-4f4c-4ad3-8ccc-baf5348f326c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMP_RL",
   "language": "python",
   "name": "amp_rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
